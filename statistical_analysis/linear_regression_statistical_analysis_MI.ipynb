{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_cases =  pd.read_csv('../results_test/ids_MI_4_test_mtdt_preds.csv') \n",
    "non_MI_cases =  pd.read_csv('../results_test/non_stroke_MI_ids_mtdt_preds.csv') \n",
    "mtdt_MI = pd.read_csv('../input_data/ids/ids_MI_4_test_mtdt.csv')\n",
    "mtdt_non_MI = pd.read_csv('../input_data/ids/non_stroke_MI_ids_mtdt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(MI_cases))\n",
    "print(len(non_MI_cases))\n",
    "print(len(mtdt_MI))\n",
    "print(len(mtdt_non_MI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MI cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtdt_MI = mtdt_MI[mtdt_MI.ID.isin(MI_cases.ID.apply(lambda x:x.split('_')[0]))]\n",
    "mtdt_MI.index = range(len(mtdt_MI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtdt_MI = mtdt_MI.sort_values(by=['ID'])\n",
    "MI_cases = MI_cases.sort_values(by=['ID'])\n",
    "MI_cases = pd.concat([MI_cases, \n",
    "                      mtdt_MI[['sex', 'dbpa', 'sbpa', 'ss', 'ads', 'bmi', 'age', 'hba1c', 'chol', 'glucose']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(MI_cases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-MI cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtdt_non_MI = mtdt_non_MI[mtdt_non_MI.ID.isin(non_MI_cases.ID.apply(lambda x:x.split('_')[0]))]\n",
    "mtdt_non_MI.index = range(len(mtdt_non_MI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtdt_non_MI = mtdt_non_MI.sort_values(by=['ID'])\n",
    "non_MI_cases = non_MI_cases.sort_values(by=['ID'])\n",
    "non_MI_cases = pd.concat([non_MI_cases, \n",
    "                      mtdt_non_MI[['sex', 'dbpa', 'sbpa', 'ss', 'ads', 'bmi', 'age', 'hba1c', 'chol', 'glucose']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(non_MI_cases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training linear regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding labels\n",
    "non_MI_cases['label'] = np.zeros((len(non_MI_cases),1))\n",
    "MI_cases['label'] = np.ones((len(MI_cases),1))\n",
    "\n",
    "# Creating data and labels\n",
    "all_vals = pd.concat([non_MI_cases.sample(n=1000), MI_cases])\n",
    "\n",
    "# Taking LVM/LVEDV or only demographics\n",
    "X = all_vals.iloc[:,3:-1].values\n",
    "# Filename\n",
    "filename_plot = 'non_lvm_lvedv'\n",
    "# labels\n",
    "y = all_vals.iloc[:,-1].values\n",
    "\n",
    "# Rescaling inputs\n",
    "scaler = RobustScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier with cross-validation and plot ROC curves\n",
    "\n",
    "# cv = StratifiedKFold(n_splits=10)\n",
    "cv = StratifiedShuffleSplit(n_splits=10, random_state=12)\n",
    "\n",
    "classifier = linear_model.LogisticRegression()\n",
    "# classifier = MLPClassifier(solver='sgd', alpha=1e-5, max_iter=1500)\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "for i, (train, test) in enumerate(cv.split(X, y)):\n",
    "       \n",
    "    classifier.fit(X[train], y[train])\n",
    "    viz = plot_roc_curve(classifier, X[test], y[test],\n",
    "                         name='ROC fold {}'.format(i),\n",
    "                         alpha=0.3, lw=1, ax=ax)\n",
    "    \n",
    "    interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    aucs.append(viz.roc_auc)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "\n",
    "ax.plot(mean_fpr, mean_tpr, color='b',\n",
    "        label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title=\"ROC\")\n",
    "ax.legend(loc=\"lower right\", fontsize=15)\n",
    "ax.tick_params(labelsize=20)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=18)\n",
    "ax.set_xlabel('False Positive Rate', fontsize=18)\n",
    "# ax.set_title('ROC - Using LVM/LVEDV', fontsize=18)\n",
    "plt.savefig(filename_plot + '.pdf')\n",
    "plt.savefig(filename_plot + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.10, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression\n",
    "## Info: https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6\n",
    "\n",
    "# lm = linear_model.LinearRegression()\n",
    "# lm = linear_model.LogisticRegression()\n",
    "lm = MLPClassifier(solver='sgd', alpha=1e-3, max_iter=1000)\n",
    "model = lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test)\n",
    "probs = lm.predict_proba(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to report confusion metrics\n",
    "def confusion_metrics (conf_matrix):\n",
    "    \n",
    "    # save confusion matrix and slice into four pieces   \n",
    "    TP = conf_matrix[1][1]\n",
    "    TN = conf_matrix[0][0]\n",
    "    FP = conf_matrix[0][1]\n",
    "    FN = conf_matrix[1][0]    \n",
    "    print('True Positives:', TP)\n",
    "    print('True Negatives:', TN)\n",
    "    print('False Positives:', FP)\n",
    "    print('False Negatives:', FN)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    conf_accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n",
    "    \n",
    "    # calculate mis-classification\n",
    "    conf_misclassification = 1 - conf_accuracy\n",
    "    \n",
    "    # calculate the sensitivity\n",
    "    conf_sensitivity = (TP / float(TP + FN))    # calculate the specificity\n",
    "    conf_specificity = (TN / float(TN + FP))\n",
    "    \n",
    "    # calculate precision\n",
    "    conf_precision = (TN / float(TN + FP))    # calculate f_1 score\n",
    "    conf_f1 = 2 * ((conf_precision * conf_sensitivity) / (conf_precision + conf_sensitivity))    \n",
    "    print('-'*50)\n",
    "    print(f'Accuracy: {round(conf_accuracy,2)}') \n",
    "    print(f'Mis-Classification: {round(conf_misclassification,2)}') \n",
    "    print(f'Sensitivity: {round(conf_sensitivity,2)}') \n",
    "    print(f'Specificity: {round(conf_specificity,2)}') \n",
    "    print(f'Precision: {round(conf_precision,2)}')\n",
    "    print(f'f_1 Score: {round(conf_f1,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "# calculate scores\n",
    "roc_auc = metrics.roc_auc_score(y_test, probs[:,1])\n",
    "# calculate roc curves\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, probs[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "confusion_metrics(cm)\n",
    "\n",
    "# Plot AUC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('ROC Curve', fontsize=18)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_MI_cases = non_MI_cases.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LVEDV\n",
    "plt.figure(figsize=(12, 10))\n",
    "non_MI_cases.iloc[:,1].hist()\n",
    "plt.title('Non MI cases', fontsize=18)\n",
    "plt.xlabel('LVEDV (ml)', fontsize=18)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.savefig('distro_non_MI_cases_LVEDV.pdf')\n",
    "plt.close()\n",
    "# LVM\n",
    "plt.figure(figsize=(12, 10))\n",
    "non_MI_cases.iloc[:,2].hist()\n",
    "plt.title('Non MI cases', fontsize=18)\n",
    "plt.xlabel('LVM (gr)', fontsize=18)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.savefig('distro_non_MI_cases_LVM.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LVEDV\n",
    "plt.figure(figsize=(12, 10))\n",
    "MI_cases.iloc[:,1].hist()\n",
    "plt.title('MI cases', fontsize=18)\n",
    "plt.xlabel('LVEDV (ml)', fontsize=18)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.savefig('distro_MI_cases_LVEDV.pdf')\n",
    "plt.close()\n",
    "\n",
    "# LVM\n",
    "plt.figure(figsize=(12, 10))\n",
    "MI_cases.iloc[:,2].hist()\n",
    "plt.title('MI cases', fontsize=18)\n",
    "plt.xlabel('LVM (gr)', fontsize=18)\n",
    "plt.ylabel('Frequency', fontsize=18)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.savefig('distro_MI_cases_LVM.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_lvedv = stats.ttest_ind(MI_cases.iloc[:,1],\n",
    "                            non_MI_cases.iloc[:,1], equal_var=False)\n",
    "print('p-value for LVEDV: ', res_lvedv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_lvm = stats.ttest_ind(MI_cases.iloc[:,2],\n",
    "                          non_MI_cases.iloc[:,2], equal_var=False)\n",
    "print('p-value for LVM: ', res_lvm[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcvae_env",
   "language": "python",
   "name": "mcvae_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
